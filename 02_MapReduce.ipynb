{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rei-L0/4-1-BigData/blob/main/02_MapReduce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00000-26bbc188-6161-4384-81d6-56e0e7fec378",
        "output_cleared": false,
        "id": "GGGT6Pl75Oqp"
      },
      "source": [
        "# Map Reduce\n",
        "\n",
        "본 코드의 목적은 map-reduce 과정을 사용하여 word count 응용을 만드는 것입니다.\n",
        "Java 버전은 여기에서 확인할 수 있습니다. [this page](https://www.dezyre.com/hadoop-tutorial/hadoop-mapreduce-wordcount-tutorial)\n",
        "\n",
        "![domain decomposition](https://github.com/Rei-L0/4-1-BigData/blob/main/images/domain_decomp.png?raw=1)\n",
        "\n",
        "credits: https://computing.llnl.gov/tutorials/parallel_comp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lorem"
      ],
      "metadata": {
        "id": "rdH6AjP65EWZ",
        "outputId": "aea75e22-34f6-478d-84e8-f34d221192cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lorem\n",
            "  Downloading lorem-0.1.1-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: lorem\n",
            "Successfully installed lorem-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lorem import text\n",
        "\n",
        "with open(\"sample.txt\", \"w\") as f:\n",
        "    for i in range(2):\n",
        "        f.write(text())"
      ],
      "metadata": {
        "id": "zlA0j92j5CBu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wc sample.txt\n",
        "du -h sample.txt"
      ],
      "metadata": {
        "id": "qZEG4Dw5492t",
        "outputId": "681a18be-1c7b-42cf-c80c-d39b63dace57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  12  330 2339 sample.txt\n",
            "4.0K\tsample.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00001-42e2deda-cde4-4a15-8613-7f6887c2b946",
        "output_cleared": false,
        "id": "f2mhNFJP5Oqv"
      },
      "source": [
        "## `map` function example\n",
        "\n",
        "`map(func, seq)` Python 함수는 함수 `func`를 시퀀스(sequence) `seq`의 모든 요소에 적용합니다.그리고 `func`에 의해 변화된 요소와 함께 새로운 리스트(list)를 반환합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "00002-da0bd233-0388-4413-b0ad-d5d8d6326966",
        "execution_millis": 8,
        "execution_start": 1604475123788,
        "output_cleared": false,
        "source_hash": "95028dd2",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jo-xD4e5Oqx",
        "outputId": "1710db96-880e-451c-9862-4b60e9f3e809"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7f7e96d1db80>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "def f(x):\n",
        "    return x * x\n",
        "\n",
        "rdd = [2, 6, -3, 7]\n",
        "res = map(f, rdd )\n",
        "res  # Res is an iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "00003-8235787f-c264-4b77-8d37-544fad7a23ee",
        "execution_millis": 4,
        "execution_start": 1604475123800,
        "output_cleared": false,
        "source_hash": "e4befbff",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdrnColo5Oqz",
        "outputId": "50905edd-9787-4eaa-920b-4499f6401bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 36 9 49\n"
          ]
        }
      ],
      "source": [
        "print(*res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cell_id": "00004-d85df79e-12a9-4d71-86f2-7fb558857de8",
        "execution_millis": 2,
        "execution_start": 1604475123811,
        "output_cleared": false,
        "source_hash": "322388ee",
        "pycharm": {
          "is_executing": true
        },
        "id": "9t1N440L5Oq1"
      },
      "outputs": [],
      "source": [
        "from operator import mul\n",
        "rdd1, rdd2 = [2, 6, -3, 7], [1, -4, 5, 3]\n",
        "res = map(mul, rdd1, rdd2 ) # element wise sum of rdd1 and rdd2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00005-992df850-d6e1-4c73-bb34-2c588ab3cfd6",
        "execution_millis": 3,
        "execution_start": 1604475123816,
        "output_cleared": false,
        "source_hash": "e4befbff",
        "pycharm": {
          "is_executing": true
        },
        "id": "L0ZSfneZ5Oq2"
      },
      "outputs": [],
      "source": [
        "print(*res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00006-82db0dbb-6add-4604-a13a-12343d8bf1ba",
        "output_cleared": false,
        "id": "L2bjbjpy5Oq2"
      },
      "source": [
        "![MapReduce](https://github.com/Rei-L0/4-1-BigData/blob/main/images/mapreduce.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00007-ab1aa2d6-1bf7-4809-8893-cb280a1a3100",
        "output_cleared": false,
        "id": "dK96jvVH5Oq2"
      },
      "source": [
        "## `functools.reduce` example\n",
        "\n",
        " `reduce(func, seq)` 함수는 시퀀스 `seq`에 함수 `func`를 연속적으로 적용한다. 예로, reduce(f, [1, 2, 3, 4, 5]) 는 f(f(f(f(1,2),3),4),5)로 동작한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cell_id": "00008-819c928c-717c-45f4-a91c-69d920cb2e4a",
        "execution_millis": 3,
        "execution_start": 1604475123824,
        "output_cleared": false,
        "source_hash": "59797020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NfIADDj5Oq3",
        "outputId": "63d619fa-df72-46ca-9aa0-8c85d8422857"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from functools import reduce\n",
        "from operator import add\n",
        "rdd = list(range(1,6))\n",
        "reduce(add, rdd) # computes ((((1+2)+3)+4)+5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00012-5cfbc3be-3d14-4ca2-b721-7ac4f5e0d1cf",
        "output_cleared": false,
        "id": "XMjo8bUP5Oq3"
      },
      "source": [
        "## 가중치 평균과 분산(Weighted mean and Variance)\n",
        "\n",
        "만약 임의 변수의 생성자\n",
        "\n",
        "임의변수 X의 생성자가 확률 질량 함수(probability mass function) $x_1 \\mapsto p_1, x_2 \\mapsto p_2, \\ldots, x_n \\mapsto p_n$ 을 가지는 이산 값이면, 다음 수식과 같이 정의된다.\n",
        "\n",
        "$$\\operatorname{Var}(X) = \\left(\\sum_{i=1}^n p_i x_i ^2\\right) - \\mu^2,$$\n",
        "\n",
        "여기서, $\\mu$ 평균값이다, i.e.\n",
        "\n",
        "$$\\mu = \\sum_{i=1}^n p_i x_i. $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00018-875fb32c-13fa-4fc5-9831-1ec50c8a4cc2",
        "output_cleared": false,
        "id": "CgBUKCci5Oq4"
      },
      "source": [
        "### Exercise 2.1\n",
        "\n",
        "반복문(for loops)를 사용하여 평균 값과 분산값을 계산하는 함수를 작성하시오"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00022-d9d47d25-2840-49dc-a6ba-1ba4e052db8b",
        "execution_millis": 1,
        "execution_start": 1604475141191,
        "output_cleared": false,
        "source_hash": "f62aea75",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJFfX-c95Oq5",
        "outputId": "f440718c-ebcd-400a-c581-98227141e717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8\n",
            "1.9600000000000002\n"
          ]
        }
      ],
      "source": [
        "X = [5, 1, 2, 3, 1, 2, 5, 4]\n",
        "P = [0.05, 0.05, 0.15, 0.05, 0.15, 0.2, 0.1, 0.25]\n",
        "\n",
        "avg=0\n",
        "var=0\n",
        "\n",
        "# 평균 구하기\n",
        "for i in range(len(X)):\n",
        "  avg+=X[i]*P[i]\n",
        "\n",
        "# 분산 구하기\n",
        "for i in range(len(X)):\n",
        "  var+=((X[i]-avg)**2)*P[i]\n",
        "\n",
        "print(avg)\n",
        "print(var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00019-1531b0c9-2685-47d5-ab7c-d9bbebc22beb",
        "output_cleared": false,
        "id": "F2EfvEk_5Oq5"
      },
      "source": [
        "### Exercise 2.2\n",
        "\n",
        "`map` 과 `reduce` 사용하여 평균 값과 분산값을 계산하는 함수를 작성하시오"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00023-23ad7ac7-c8c3-4054-b953-0b50ecc4c758",
        "output_cleared": false,
        "id": "95o7GC8m5Oq6"
      },
      "source": [
        "* Exercise 는 map-reduce 과정을 이해하는데 사용하는 것이며, 실제로 분산을 구하는 것은 [Numpy](http://www.numpy.org) 라이브러리를 사용해야합니다*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import mul,add\n",
        "\n",
        "avg=reduce(add,list(map(mul,X,P)))\n",
        "avg_l=[avg]*len(X)\n",
        "var=reduce(add,list(map(mul,map(lambda x,y:(x-y)**2,X,avg_l),P)))\n",
        "\n",
        "print(avg)\n",
        "print(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08SOBxQ87wX3",
        "outputId": "9859b206-913f-4ab2-8dbd-bebc61ecc0c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8\n",
            "1.9600000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00024-ced56325-0795-4661-8e25-d8b2403ac700",
        "output_cleared": false,
        "id": "ayWp7s-e5Oq6"
      },
      "source": [
        "## Wordcount \n",
        "\n",
        "\n",
        "우리는 `wordcount` 응용을 map-reduce 과정과 함께 수정할 것입니다.\n",
        "여기서, `map`은 text files을 입력으로 취하고 words들로 분리합니다. 그리고  `reduce` 과정은 각 words의 등장 숫자를 합(sum)하여, key/value 쌍형태로 내보냅니다.\n",
        "\n",
        "우리는 다음 예제 [Hadoop documentation](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Example:_WordCount_v1.0) Python에서 구현하고자 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00025-167cf7a3-3497-4f98-b6bc-8b38bcf7d641",
        "output_cleared": false,
        "id": "nK6vKV9q5Oq6"
      },
      "source": [
        "## Map - Read file and return a key/value pairs\n",
        "\n",
        "### Exercise 2.3\n",
        "\n",
        "`mapper` 함수를 작성하시오. 이 함수는 하나의 file name을 입력으로 취하고, (word, 1) 튜플(tuples)의 정렬된 시퀀스를 반환합니다.\n",
        "Write a function `mapper` with a single file name as input that returns a sorted sequence of tuples (word, 1) values.\n",
        "\n",
        "```pybt\n",
        "mapper('sample.txt')\n",
        "[('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('amet', 1), ('amet', 1), ('amet', 1)...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mapper(filename):\n",
        "  f=open(filename,'r')\n",
        "  words=f.read().split()\n",
        "  word_count=[]\n",
        "  for i in words:\n",
        "    word_count.append((i,1))\n",
        "  return word_count\n",
        "mapper('sample.txt')"
      ],
      "metadata": {
        "id": "hE0crz_xlgAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00026-2a461c17-a231-43d2-bdee-f683a2912bf4",
        "output_cleared": false,
        "id": "nRMPtrX25Oq7"
      },
      "source": [
        "## Partition\n",
        "\n",
        "### Exercise 2.4\n",
        "\n",
        "`partitioner` 함수를 작성하시오. 이 함수는 mapper로부터 key/value 쌍을 저장하고 mapper는 (word,1)을 리스트 형태로 그룹화 합니다\n",
        "\n",
        "```python\n",
        "partitioner(mapper('sample.txt'))\n",
        "[('adipisci', [1, 1, 1, 1, 1, 1, 1]), ('aliquam', [1, 1, 1, 1, 1, 1, 1]), ('amet', [1, 1, 1, 1],...]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def partitioner(list):\n",
        "  word_count_p=dict()\n",
        "  for i in list:\n",
        "    i=list(i)\n",
        "    if i not in word_count_p:\n",
        "      word_count_p[i[0]]=i[1]\n",
        "    else:\n",
        "      word_count_p[i].append(1)\n",
        "      \n",
        "  return word_count_p\n",
        "\n",
        "partitioner('sample.txt')\n"
      ],
      "metadata": {
        "id": "nmisJmKv5m3A",
        "outputId": "475bffeb-12c5-4d5b-d4f5-80c464de1438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-814a7542ae3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mword_count_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpartitioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-814a7542ae3a>\u001b[0m in \u001b[0;36mpartitioner\u001b[0;34m(list)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mword_count_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_count_p\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mword_count_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00027-20fa8411-911d-450d-a524-6e0dbcf66864",
        "output_cleared": false,
        "id": "f1jgd0Pm5Oq8"
      },
      "source": [
        "## Reduce - Sums the counts and returns a single key/value (word, sum).\n",
        "\n",
        "### Exercise 2.5\n",
        "\n",
        "`reducer` 함수를 작성하시오. 이 함수는 `(word,[1,1,1,..,1])` 튜플을 읽어서 word의 발생을 합(sum)하고,  튜플 (word, 발생 횟수)를 출력한다.\n",
        "\n",
        "```python\n",
        "reducer(('hello',[1,1,1,1,1])\n",
        "('hello',5)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00028-5a02ce56-1aaa-4a72-bccb-5fa1bcd6ba4b",
        "output_cleared": false,
        "id": "vjZ3KYOC5Oq9"
      },
      "source": [
        "## Process several files\n",
        "\n",
        "다음 예제는 8개의 파일 `sample[00-07].txt`을 만들고. 가장 자주 등장하는 단어에 대한 파일을 출력의 맨 위에 설정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00029-b2c70e85-cb81-48d2-b1ab-f433e60defbf",
        "execution_millis": 11,
        "execution_start": 1604475141331,
        "output_cleared": false,
        "source_hash": "35d25c27",
        "id": "xfOnQgE85Oq-"
      },
      "outputs": [],
      "source": [
        "from lorem import text\n",
        "for i in range(1):\n",
        "    with open(\"sample{0:02d}.txt\".format(i), \"w\") as f:\n",
        "        f.write(text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00030-a5da7b68-98d0-4e0d-a5dc-a0bd8e821ff5",
        "execution_millis": 1,
        "execution_start": 1604475141355,
        "output_cleared": false,
        "source_hash": "8bf0ba7a",
        "id": "l3m5fOcr5Oq-"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "files = sorted(glob.glob('sample0*.txt'))\n",
        "files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00031-846589d9-1c68-491d-84cf-6437d569e71f",
        "output_cleared": false,
        "id": "ADAHbTQC5Oq_"
      },
      "source": [
        "### Exercise 2.6\n",
        "\n",
        "파일과 파티션된 데이터 위의 반복문을 사용하여 (word, occurrences)를 세는 함수를 구현하시오"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00032-24f070e4-4ef6-4d4e-88ac-14062d615832",
        "output_cleared": false,
        "id": "pMiAX8DT5Oq_"
      },
      "source": [
        "### Exercise 2.7\n",
        "\n",
        "이번에는, `my_map_reduce` 함수를 작성하시오. 이 함수는 mapper, partitioner, 그리고 reducer를 포함한다.\n",
        "\n",
        "```python\n",
        " my_map_reduce(files)\n",
        " [('hello',5), ('nice',3), ..., ]\n",
        "```\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "46324081-d535-42b5-844e-a6aaf89c3a71",
    "kernelspec": {
      "display_name": "big-data",
      "language": "python",
      "name": "big-data"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}